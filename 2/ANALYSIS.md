# Анализ результатов


## Описание файлов

### 1. homework_model_modification.py

Реализация моделей машинного обучения:
- `LinearRegression`: линейная регрессия с L1/L2 регуляризацией
- `MulticlassLogisticRegression`: многоклассовая логистическая регрессия

Функционал:
- Регуляризация
- Сохранение/загрузка моделей
- Early stopping
- Логирование процесса обучения

### 2. homework_datasets.py

Классы для работы с данными:
- `CSVDataset`: загрузка и предобработка CSV-файлов
- Поддержка задач регрессии и классификации
- Автоматическая обработка категориальных признаков
- Нормализация данных

### 3. homework_experiments.py

Проведение экспериментов:
1. Исследование гиперпараметров:
   - Learning rate (0.001, 0.01, 0.1)
   - Batch size (16, 32, 64)
   - Оптимизаторы (SGD, Adam, RMSprop)

2. Feature Engineering:
   - Полиномиальные признаки
   - Признаки взаимодействия
   - Статистические признаки

## Результаты экспериментов

### 1. cars_moldova_cat_num.csv (регрессия)

**Лучшая конфигурация:**
- Оптимизатор: SGD
- Learning rate: 0.01
- Batch size: 32
- MSE: 47.1M (базовые признаки), 28.8M (полиномиальные)

**Выводы:**
- Adam/RMSprop приводят к расходимости
- Полиномиальные признаки улучшают результат на 39%
- Batch size незначительно влияет на качество

### 2. Raisin_Dataset.csv (классификация)

**Лучшая конфигурация:**
- Оптимизатор: Adam
- Learning rate: 0.01
- Batch size: 64
- Accuracy: 87.2%

**Выводы:**
- Adam показывает лучшие результаты для классификации
- Увеличение batch size может улучшать accuracy

### 3. Tesla.csv (регрессия)

**Лучшая конфигурация:**
- Оптимизатор: SGD
- Learning rate: 0.1
- Batch size: 32
- MSE: 4.90 (базовые признаки)

**Выводы:**
- Высокий learning rate (0.1) работает лучше
- Полиномиальные признаки ухудшают качество

